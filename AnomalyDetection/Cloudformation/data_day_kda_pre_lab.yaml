AWSTemplateFormatVersion: 2010-09-09
Description: Supporting elements for the Kinesis Analytics click stream lab
Parameters:
  email:
    Description: Email address to send anomaly detection events.
    Type: String
  SMS:
    Description: Mobile Phone number to send SMS anomaly detection events. +1XXXXXXXXXX
    Type: String
  Username:
    Description: The username of the user you want to create in Amazon Cognito.
    Type: String
    AllowedPattern: "^(?=\\s*\\S).*$"
    ConstraintDescription: Cannot be empty
  Password:
    Description: The password of the user you want to create in Amazon Cognito. Must be at least 6 alpha-numeric characters, and contain at least one number
    Type: String
    NoEcho: true
    AllowedPattern: "^(?=.*[A-Za-z])(?=.*\\d)[A-Za-z\\d]{6,}$"
    ConstraintDescription: Must be at least 6 alpha-numeric characters, and contain at least one number
  FlinkVersion:
    Description: Flink version to build
    Type: String
    Default: 1.15.4
    AllowedPattern: \d\.\d\d\.\d
  Release:
    Description: Github branch or release to be used for the consumer application
    Type: String
    Default: master
  GlueDatabaseName:
    Description: Glue Database Name to associate with KDA Notebook
    Type: String
    Default: prelab_kda_db
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: "Kinesis Pre Lab set up"
        Parameters:
          - "Username"
          - "Password"
          - "email"
          - "SMS"
Resources:
  RawS3Bucket:
    Type: AWS::S3::Bucket
  ProcessedS3Bucket:
    Type: AWS::S3::Bucket
  S3Role:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Service: firehose.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                sts:ExternalId: !Ref AWS::AccountId
      Policies:
        -
          PolicyName: S3Access
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Effect: Allow
                Action:
                  - "s3:*"
                Resource:
                  - !Sub arn:aws:s3:::${RawS3Bucket}
                  - !Sub arn:aws:s3:::${RawS3Bucket}/*
        -
          PolicyName: CloudWatch
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Effect: Allow
                Action:
                  - "cloudwatch:*"
                  - "cloudwatchlogs:*"
                Resource:
                  - "*"
  DataGenCognitoSetupLambdaFunc:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        S3Bucket: !Sub aws-kdg-tools-${AWS::Region}
        S3Key: datagen-cognito-setup.zip
      Description: Creates a Cognito User Pool, Identity Pool, and a User.  Returns IDs to be used in the Kinesis Data Generator.
      FunctionName: KinesisDataGeneratorCognitoSetup
      Handler: createCognitoPool.createPoolAndUser
      Role: !GetAtt CognitoLambdaExecutionRole.Arn
      Runtime: nodejs16.x
      Timeout: 900
  CognitoLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        -
          PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Effect: Allow
                Action:
                  - logs:*
                Resource: !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*
              -
                Effect: Allow
                Action:
                  - cognito-idp:AdminConfirmSignUp
                  - cognito-idp:CreateUserPoolClient
                  - cognito-idp:AdminCreateUser
                Resource:
                  - !Sub arn:aws:cognito-idp:${AWS::Region}:${AWS::AccountId}:userpool/*
              -
                Effect: Allow
                Action:
                  - cognito-idp:CreateUserPool
                  - cognito-identity:*
                Resource: "*"
              -
                Effect: Allow
                Action:
                  - iam:UpdateAssumeRolePolicy
                Resource:
                  - !GetAtt AuthenticatedUserRole.Arn
                  - !GetAtt UnauthenticatedUserRole.Arn
              -
                Effect: Allow
                Action:
                  - iam:PassRole
                Resource:
                  - !GetAtt AuthenticatedUserRole.Arn
                  - !GetAtt UnauthenticatedUserRole.Arn
  SetupCognitoCustom:
    Type: Custom::DataGenCognitoSetupLambdaFunc
    Properties:
      ServiceToken: !GetAtt DataGenCognitoSetupLambdaFunc.Arn
      Region: !Ref AWS::Region
      Username: !Ref Username
      Password: !Ref Password
      AuthRoleName: !Ref AuthenticatedUserRole
      AuthRoleArn: !GetAtt AuthenticatedUserRole.Arn
      UnauthRoleName: !Ref UnauthenticatedUserRole
      UnauthRoleArn: !GetAtt UnauthenticatedUserRole.Arn
  AuthenticatedUserRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Federated:
                - cognito-identity.amazonaws.com
            Action:
              - sts:AssumeRoleWithWebIdentity
      Path: /
      Policies:
        -
          PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Action:
                  - kinesis:DescribeStream
                  - kinesis:PutRecord
                  - kinesis:PutRecords
                Resource:
                  - !Sub arn:aws:kinesis:${AWS::Region}:${AWS::AccountId}:stream/*
                Effect: Allow
              -
                Action:
                  - firehose:DescribeDeliveryStream
                  - firehose:PutRecord
                  - firehose:PutRecordBatch
                Resource:
                  - !Sub arn:aws:firehose:${AWS::Region}:${AWS::AccountId}:deliverystream/*
                Effect: Allow
              -
                Action:
                  - mobileanalytics:PutEvents
                  - cognito-sync:*
                  - cognito-identity:*
                  - ec2:DescribeRegions
                  - firehose:ListDeliveryStreams
                  - kinesis:ListStreams
                Resource:
                  - "*"
                Effect: Allow
  UnauthenticatedUserRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Federated:
                - cognito-identity.amazonaws.com
            Action:
              - sts:AssumeRoleWithWebIdentity
      Path: /
      Policies:
        -
          PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Effect: Allow
                Action:
                  - mobileanalytics:PutEvents
                  - cognito-sync:*
                Resource:
                  - "*"
  CSELambdaSNSPublishRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        -
          PolicyName: lambda_sns
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Effect: Allow
                Action:
                  - sns:Publish
                Resource: !Ref CSEClickStreamEvent
  CSEClickStreamEvent:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: ClkStrEv2
      Subscription:
        -
          Endpoint: !Ref email
          Protocol: email
        -
          Endpoint: !Ref SMS
          Protocol: sms
      TopicName: ClickStreamEvent2
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        -
          PolicyName: CSELambdaExecutionRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Sid: publish2sns
                Effect: Allow
                Action:
                  - sns:Publish
                Resource:
                  - !Ref CSEClickStreamEvent
              -
                Sid: writelogs
                Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*
              -
                Sid: readkinesis
                Effect: Allow
                Action:
                  - kinesis:DescribeStream
                  - kinesis:GetRecords
                  - kinesis:GetShardIterator
                  - kinesis:ListStreams
                Resource: "*"
              -
                Action:
                  - s3:PutObject
                Resource: !Sub arn:aws:s3:::${ProcessedS3Bucket}/*
                Effect: Allow
                Sid: writeToS3
        - 
          PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Resource: "*"
                Effect: Allow
                Action:
                  - codepipeline:PutJobSuccessResult
                  - codepipeline:PutJobFailureResult
              - Resource:
                  - arn:aws:logs:*:*:log-group:/aws/lambda/*
                  - arn:aws:logs:*:*:log-group:/aws/lambda/*:log-stream:*
                Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
              - Resource:
                  - !Sub arn:aws:s3:::${ArtifactBucket}
                  - !Sub arn:aws:s3:::${ArtifactBucket}/*
                Effect: Allow
                Action:
                  - s3:PutObject
  CSEBeconAnomalyResponse:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: !Sub |
          var AWS = require('aws-sdk');
          var sns = new AWS.SNS( { region: '${AWS::Region}' });
          var s3 = new AWS.S3();

          exports.handler = function(event, context) {
            console.log(JSON.stringify(event, null, 3));
            event.Records.forEach(function(record) {
              var payload = new Buffer(record.kinesis.data, 'base64').toString('ascii');
              var rec = JSON.parse(payload);
              var ctr = rec.ctrpercent;
              var anomaly_score = rec.anomaly_score;
              var detail = 'Anomaly detected with a click through rate of ' + ctr + '% and an anomaly score of ' + anomaly_score;
              var subject = 'Anomaly Detected';
              var SNSparams = {
                Message: detail,
                MessageStructure: 'String',
                Subject: subject,
                TopicArn: '${CSEClickStreamEvent}'
              };
              sns.publish(SNSparams, function(err, data) {
                if (err) context.fail(err.stack);
                else{
                  var anomaly = [{
                    'date': Date.now(),
                    'ctr': ctr,
                    'anomaly_score': anomaly_score
                  }]

                  convertArrayOfObjectsToCSV({ data: anomaly }, function(err1, data1){
                    if(err1) context.fail(err1.stack); // an error occurred
                    else{
                      var today = new Date();
                      var S3params = {
                        'Bucket': '${ProcessedS3Bucket}',
                        'Key': `weblogs/processed/${!today.getFullYear()}/${!today.getMonth()}/${!today.getDate()}/${!record.recordId}.csv`,
                        'Body': data1,
                        'ContentType': 'text/csv'
                      }
                      s3.putObject(S3params, function(err2, data2) {
                        if (err2) context.fail(err2.stack); // an error occurred
                        else {
                          context.succeed('Published Notification'); // successful response
                        }
                      })
                    }
                  })
                }
              });
            });
          };

          function convertArrayOfObjectsToCSV(args, callback) {
            var result, ctr, keys, columnDelimiter, lineDelimiter, data;
            data = args.data || null;
            if (data == null || !data.length) {
              callback(new Error('data is null'));
            }
            columnDelimiter = args.columnDelimiter || ',';
            lineDelimiter = args.lineDelimiter || ',';
            keys = Object.keys(data[0]);
            result = '';
            result += keys.join(columnDelimiter);
            result += lineDelimiter;
            data.forEach(function(item) {
              ctr = 0;
              keys.forEach(function(key) {
                  if (ctr > 0) result += columnDelimiter;
                  result += item[key];
                      ctr++;
                  });
                  result += lineDelimiter;
            });
            callback(null, result);
          }
      Description: Click Stream Example Lambda Function
      FunctionName: CSEBeconAnomalyResponse
      Handler: index.handler
      MemorySize: 128
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: nodejs16.x
      Timeout: 60
  CSEKinesisAnalyticsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Service:
                - kinesisanalytics.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        -
          PolicyName: firehose
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              -
                Sid: UseLambdaFunction
                Effect: Allow
                Action:
                  - lambda:InvokeFunction
                  - lambda:GetFunctionConfiguration
                Resource:
                  - !Sub ${CSEBeconAnomalyResponse.Arn}:$LATEST
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: LambdaRolePolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action: s3:DeleteObject
                Resource:
                  - !Sub arn:aws:s3:::${RawS3Bucket}/*
                  - !Sub arn:aws:s3:::${ProcessedS3Bucket}/*
              - Effect: Allow
                Action: s3:ListBucket
                Resource:
                  - !Sub arn:aws:s3:::${RawS3Bucket}
                  - !Sub arn:aws:s3:::${ProcessedS3Bucket}
              - Effect: Allow
                Action: logs:CreateLogGroup
                Resource: !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:*
  S3BucketHandler:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaRole.Arn
      Code:
        ZipFile: |
          import os
          import json
          import cfnresponse
          import boto3
          from botocore.exceptions import ClientError

          s3 = boto3.resource('s3')


          def handler(event, context):
              print("Received event: %s" % json.dumps(event))
              s3_bucket = s3.Bucket(event['ResourceProperties']['Bucket'])

              try:
                  if event['RequestType'] == 'Create' or event['RequestType'] == 'Update':
                      result = cfnresponse.SUCCESS
                  elif event['RequestType'] == 'Delete':
                      s3_bucket.objects.delete()
                      result = cfnresponse.SUCCESS
              except ClientError as e:
                  print('Error: %s', e)
                  result = cfnresponse.FAILED

              cfnresponse.send(event, context, result, {})

      Runtime: python3.8
      Timeout: 300

  EmptyRawS3Bucket:
    Type: "Custom::EmptyS3Bucket"
    Properties:
      ServiceToken: !GetAtt S3BucketHandler.Arn
      Bucket: !Ref RawS3Bucket

  EmptyProcessedS3Bucket:
    Type: "Custom::EmptyS3Bucket"
    Properties:
      ServiceToken: !GetAtt S3BucketHandler.Arn
      Bucket: !Ref ProcessedS3Bucket

  CSEBeconAnomalyEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      EventSourceArn:
        Fn::Join: 
          - ""
          -
            - "arn:aws:kinesis:"
            - !Ref AWS::Region
            - ":"
            - !Ref AWS::AccountId
            - ":stream/"
            - !Ref AnomalyDetectionStream
      FunctionName: !GetAtt CSEBeconAnomalyResponse.Arn
      StartingPosition: "LATEST"
  
  ArtifactBucket:
    Type: AWS::S3::Bucket
    Properties:
      VersioningConfiguration:
        Status: Enabled

  BuildPipeline:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      RoleArn: !GetAtt CodePipelineServiceRole.Arn
      Stages:
        - Name: Source
          Actions:
            - Name: RcfExampleSourceAction
              ActionTypeId:
                Category: Source
                Owner: AWS
                Version: "1"
                Provider: S3
              OutputArtifacts:
                - Name: RcfExampleSource
              Configuration:
                S3Bucket: !Ref ArtifactBucket
                S3ObjectKey: sources/amazon-kinesis-analytics-rcf-example.zip
              RunOrder: 1
        - Name: BuildRcfExample
          Actions: 
            - Name: BuildRcfExample
              InputArtifacts:
                - Name: RcfExampleSource
              OutputArtifacts:
                - Name: BuildRcfExampleOutput
              ActionTypeId:
                Category: Build
                Owner: AWS
                Version: "1"
                Provider: CodeBuild
              Configuration:
                ProjectName: !Ref RcfExampleBuildProject
                PrimarySource: RcfExampleSource
              RunOrder: 1
        - Name: Copy
          Actions:
            - Name: CopyRcfExample
              InputArtifacts:
                - Name: BuildRcfExampleOutput
              ActionTypeId:
                Category: Deploy
                Owner: AWS
                Version: "1"
                Provider: S3
              Configuration:
                BucketName: !Ref ArtifactBucket
                Extract: true
              RunOrder: 1
            - Name: NotifyCloudformation
              ActionTypeId:
                Category: Invoke
                Owner: AWS
                Version: "1"
                Provider: Lambda
              Configuration:
                FunctionName: !Ref NotifyWaitConditionLambdaFunction
              RunOrder: 2
      ArtifactStore:
        Type: S3
        Location: !Ref ArtifactBucket

  BuildCompleteWaitCondition:
    Type: AWS::CloudFormation::WaitCondition
    Properties:
      Count: 1
      Handle: !Ref BuildCompleteWaitHandle
      Timeout: "900"

  BuildCompleteWaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle

  RcfExampleBuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      ServiceRole: !GetAtt CodeBuildServiceRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_LARGE
        Image: aws/codebuild/java:openjdk-11
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
          version: 0.2

          phases:
            build:
              commands:
                - 'cd amazon-kinesis-data-analytics-examples-* || :'
                - 'cd AnomalyDetection/RandomCutForest || :'
                - mvn clean package -B -Dflink.version=${FlinkVersion}

          artifacts:
            files:
              - target/flink-random-cut-forest-example-*.jar
              - amazon-kinesis-data-analytics-examples-*/AnomalyDetection/RandomCutForest/target/flink-random-cut-forest-example-*.jar
            discard-paths: yes
      TimeoutInMinutes: 5

  NotifyWaitConditionLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: !Sub |
          import json
          import boto3
          import urllib.request

          code_pipeline = boto3.client('codepipeline')

          def handler(event, context):
            job_id = event['CodePipeline.job']['id']

            url = '${BuildCompleteWaitHandle}'
            headers = { "Content-Type": "" }
            data = { "Status": "SUCCESS", "Reason": "Compilation Succeeded", "UniqueId": "RcfExampleBuildProject", "Data": "Compilation Succeeded" }

            try:
              req = urllib.request.Request(url, headers=headers, data=bytes(json.dumps(data), encoding="utf-8"), method='PUT')
              response = urllib.request.urlopen(req)

              code_pipeline.put_job_success_result(jobId=job_id)
            except Exception as e:
              print("failure: " + str(e))
              code_pipeline.put_job_failure_result(jobId=job_id, failureDetails={'message': str(e), 'type': 'JobFailed'})

      Runtime: python3.9
      Timeout: 10

  DownloadSources:
    Type: Custom::DownloadSources
    Properties:
      ServiceToken: !GetAtt DownloadSourcesFunction.Arn

  DownloadSourcesFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: !Sub |
          import boto3
          import cfnresponse
          from urllib.request import urlopen

          def handler(event, context):
            s3 = boto3.client('s3')
            rcf_example_source = urlopen('https://github.com/duttaabhijit06/amazon-kinesis-data-analytics-examples/archive/${Release}.zip')

            s3.put_object(Bucket='${ArtifactBucket}',Key='sources/amazon-kinesis-analytics-rcf-example.zip',Body=rcf_example_source.read())

            cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
      Runtime: python3.9
      Timeout: 60

  CodePipelineServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      AssumeRolePolicyDocument: !Sub |
        {
            "Statement": [{
                "Effect": "Allow",
                "Principal": { "Service": [ "codepipeline.amazonaws.com" ]},
                "Action": [ "sts:AssumeRole" ]
            }]
        }
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Resource:
                  - !Sub arn:aws:s3:::${ArtifactBucket}
                  - !Sub arn:aws:s3:::${ArtifactBucket}/*
                Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                  - s3:GetObjectVersion
                  - s3:GetBucketVersioning
              - Resource:
                  - !Sub ${RcfExampleBuildProject.Arn}
                Effect: Allow
                Action:
                  - codebuild:StartBuild
                  - codebuild:BatchGetBuilds
              - Resource: !Sub ${NotifyWaitConditionLambdaFunction.Arn}
                Effect: Allow
                Action:
                  - lambda:InvokeFunction
                  - lambda:InvokeAsync

  CodeBuildServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      AssumeRolePolicyDocument: !Sub |
        {
            "Statement": [{
                "Effect": "Allow",
                "Principal": { "Service": [ "codebuild.amazonaws.com" ]},
                "Action": [ "sts:AssumeRole" ]
            }]
        }
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Resource:
                  - arn:aws:logs:*:*:log-group:/aws/codebuild/*
                  - arn:aws:logs:*:*:log-group:/aws/codebuild/*:log-stream:*
                Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
              - Resource:
                  - !Sub arn:aws:s3:::${ArtifactBucket}
                  - !Sub arn:aws:s3:::${ArtifactBucket}/*
                Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:GetObjectVersion
                  - s3:ListBucket
  
  TickerStream:
    Type: 'AWS::Kinesis::Stream'
    Properties:
      Name: !Sub 'websitevisits'
      ShardCount: 1
  
  ClickStream:
    Type: 'AWS::Kinesis::Stream'
    Properties:
      Name: !Sub 'clickstream'
      ShardCount: 1

  ImpressionStream:
    Type: 'AWS::Kinesis::Stream'
    Properties:
      Name: !Sub 'impressionstream'
      ShardCount: 1

  CtrStream:
    Type: 'AWS::Kinesis::Stream'
    Properties:
      Name: !Sub 'ctrstream'
      ShardCount: 1

  DestinationStream:
    Type: 'AWS::Kinesis::Stream'
    Properties:
      Name: !Sub 'destinationstream'
      ShardCount: 1

  AnomalyDetectionStream:
    Type: 'AWS::Kinesis::Stream'
    Properties:
      Name: !Sub 'anomalydetectionstream'
      ShardCount: 1

  KDAFlinkApplication:
    Type: 'AWS::KinesisAnalyticsV2::Application'
    Properties:
      ApplicationName: !Sub '${AWS::StackName}-rcfExample'
      ApplicationDescription: >-
        This application computes anomaly score via RandomCutForest algorithm
      RuntimeEnvironment: FLINK-1_15
      ServiceExecutionRole: !GetAtt ServiceExecutionRole.Arn
      ApplicationConfiguration:
        ApplicationCodeConfiguration:
          CodeContent:
            S3ContentLocation:
              BucketARN: !GetAtt ArtifactBucket.Arn
              FileKey: >-
                flink-random-cut-forest-example-1.0.jar
          CodeContentType: ZIPFILE
        FlinkApplicationConfiguration:
          MonitoringConfiguration:
            ConfigurationType: CUSTOM
            LogLevel: INFO
            MetricsLevel: APPLICATION
        EnvironmentProperties:
          PropertyGroups:
            - PropertyGroupId: RcfExampleEnvironment
              PropertyMap:
                region: !Sub ${AWS::Region}'
                initialPosition: !Sub 'TRIM_HORIZON'
                inputStreamName: !Ref CtrStream
                outputStreamName: !Ref DestinationStream
    DependsOn: BuildCompleteWaitCondition

  ServiceExecutionRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: kinesisanalytics.amazonaws.com
            Action: 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: Open
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'kinesis:*'
                Resource:
                  - !GetAtt CtrStream.Arn
              - Effect: Allow
                Action:
                  - 'kinesis:*'
                Resource:
                  - !GetAtt DestinationStream.Arn
              - Effect: Allow
                Action:
                  - 'logs:CreateLogStream'
                  - 'logs:CreateLogGroup'
                  - 'logs:PutDestination'
                  - 'logs:CreateLogDelivery'
                  - 'logs:PutLogEvents'
                Resource: '*'
              - Effect: Allow
                Action:
                  - 's3:ListBucket'
                  - 's3:GetObject'
                Resource: !Sub
                  - 'arn:aws:s3:::${ArtifactBucketPlaceholder}/flink-random-cut-forest-example-1.0.jar'
                  - ArtifactBucketPlaceholder: !Ref ArtifactBucket
  
  AnomalyDetectionApplication:
    Type: AWS::KinesisAnalyticsV2::Application
    Properties:
      ApplicationMode: INTERACTIVE
      RuntimeEnvironment: ZEPPELIN-FLINK-3_0
      ServiceExecutionRole: !GetAtt KinesisAnalyticsServiceExecutionRole.Arn
      ApplicationConfiguration:
        FlinkApplicationConfiguration:
          ParallelismConfiguration:
            Parallelism: 12
            ConfigurationType: CUSTOM
        ZeppelinApplicationConfiguration:
          CatalogConfiguration:
            GlueDataCatalogConfiguration:
              DatabaseARN: !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${GlueDatabase}"
          CustomArtifactsConfiguration:
            - ArtifactType: DEPENDENCY_JAR
              MavenReference:
                GroupId: org.apache.flink
                ArtifactId: flink-sql-connector-kinesis
                Version: 1.15.4
            - ArtifactType: DEPENDENCY_JAR
              MavenReference:
                GroupId: org.apache.flink
                ArtifactId: flink-connector-kafka
                Version: 1.15.4
            - ArtifactType: DEPENDENCY_JAR
              MavenReference:
                GroupId: software.amazon.msk
                ArtifactId: aws-msk-iam-auth
                Version: 1.1.6

  GlueDatabase:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Ref GlueDatabaseName
        Description: My glue database

  KinesisAnalyticsServiceExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: kinesisanalytics.amazonaws.com
            Action: 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: glue-kinesis-access
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - glue:*
                  - kinesis:*
                  - kinesisanalytics:*
                Resource:
                  - '*'
Outputs:
  KinesisDataGeneratorUrl:
    Description: The URL for your Kinesis Data Generator.
    Value: !Sub https://awslabs.github.io/amazon-kinesis-data-generator/web/producer.html?${SetupCognitoCustom.Querystring}
  RawBucketName:
    Description: This the bucket name of where your Raw data will be store at
    Value: !Ref RawS3Bucket
  ProcessedBucketName:
    Description: This the bucket name of where your Processed data will be store at
    Value: !Ref ProcessedS3Bucket
